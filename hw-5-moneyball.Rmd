---
title: "Homework 5"
output: html_document
---

```{r, message=FALSE, warning=FALSE}
library(Lahman)
library(tidyverse)
library(broom)
```

# Problem 1 - Money Ball

_Moneyball: The Art of Winning an Unfair Game_ is a book by Michael Lewis about the Oakland Athletics baseball team in 2002 and its general manager, the person tasked with building the team, Billy Beane. During Billy Bean's tenure as general manager, ownership cut the budget drastically leaving the general manager with one of the lowest payrolls in baseball. Money Ball tells the story of how Billy Bean used analysts to find inefficiencies in the market. Specifically, his team used data science to find low cost players that the data predicted would help the team win.

Statistics have been used in baseball since its beginnings. Note that `Lahman` (a library containing an extensive baseball database) goes back to the 19th century. Batting average, for example, has been used to summarize a batter's success for decades. [Other statistics](http://mlb.mlb.com/stats/league_leaders.jsp) such as home runs (HR), runs batted in (RBI) and stolen bases have been reported and players rewarded for high numbers. However, until [Bill James](https://en.wikipedia.org/wiki/Bill_James) introduced [sabermetrics](https://en.wikipedia.org/wiki/Sabermetrics), careful analyses had not been done to determine if these statistics actually help a team win. To simplify the exercise we will focus on scoring runs and ignore pitching and fielding. 

## Problem 1A

Here, we will use the `Lahman` library. You can see tables that are available when you load this package by typing:

```{r, eval=FALSE}
?Lahman
library(Lahman)
library(dplyr)
library(ggplot2)
```

Use the data in the `Teams` table to explore the relationship between stolen bases (SB) and runs per game in 1999. Make a plot, fit a regression line, and report the coefficients. If you take the coefficient at face value, how many more runs per game does a team score for every extra SB per game?

```{r}
teams <- Teams
teams99 <- teams %>% filter(yearID == 1999) %>% 
  mutate(SB_per_game = SB/G, R_per_game = R/G) 

# Plot the data with the regression line
ggplot(data = teams99, aes(SB_per_game,R_per_game)) + geom_point() + geom_smooth(method = "lm")

# Compute the regression and extract the beta 1 coefficient
runs_bases <- lm(R_per_game~SB_per_game, data = teams99)
runs_bases$coefficients[2]
```

Therefore, for every extra stolen base per game, there is a `r runs_bases$coefficients[2]` increase in the mean number of runs per game.

## Problem 1B

In Problem 1A we observed a positive relationship between scoring runs and stealing bases. However, the estimated slope coefficient is a random variable. There is chance involved in scoring a run. So how do we know if this observed relationship was not just chance variability?

To examine the variability of this random variable we will consider each year to be a new independent outcome. Use the `lm` and `do` functions to fit a linear model to each year since 1961 (when they started playing 162 games per year). Hint: use the function `tidy` in `broom` to process the regression in each group so that it can be recombined (see [here](https://cran.r-project.org/web/packages/broom/vignettes/broom_and_dplyr.html) for examples).

Using this approach, what is your estimate of the slope random variable's standard error? Is the distribution of the random variable well approximated by a normal distribution? If so, use this to provide a 95% confidence interval for our effect of stolen bases on runs per game. Do you think stolen bases help score runs?


```{r}
library(broom)
library(tibble)
library(purrr)
library(tidyr)

# Filter the data for teams from 1961 onward
teams61onward <- teams %>% filter(yearID >= 1961) %>% 
  mutate(SB_per_game = SB/G, R_per_game = R/G) 

teams61onward <- as.tibble(teams61onward)

# Tidy all of the regressions per year into one dataframe
reg61on_data <- teams61onward %>%
  nest(-yearID) %>% 
  mutate(
    fit = map(data, ~ lm(R_per_game ~ SB_per_game, data = .x)),
    tidied = map(fit, tidy)
  ) %>% 
  unnest(tidied)

# filter the data for just the SB estimates and then take SD
est61on_se <- reg61on_data %>% 
  filter(term == "SB_per_game") 

sd(est61on_se$estimate)

# Plot the SB estimates
ggplot(data = est61on_se, aes(estimate)) + geom_histogram(fill="royal blue")

# 95 % CI for the effect of stolen bases on runs
ci_sb_runs <- c(mean(est61on_se$estimate)-1.96*sd(est61on_se$estimate)/sqrt(length(est61on_se$yearID)), mean(est61on_se$estimate)+1.96*sd(est61on_se$estimate)/sqrt(length(est61on_se$yearID)))

ci_sb_runs
```

Thus from the table containing a regression for each year of stolen bases per game on runs per game, we have the standard error of the SB_per_game estimates to be `r sd(est61on_se$estimate)`. Upon plotting a histogram of the estimates, they appear to be decently approximated by a Normal Distribution, however it would be beneficial to have more data to see if the middle portions of the graph continued to become dense while the tails remain small. Based on the 95% CI I do not believe that stolen bases help score runs as this confidence interval `r ci_sb_runs` contains 0 which indicates an insignificant effect on the response.

## Problem 1C

Even if we didn't have several years to examine the distribution of our estimate, there is a version of the CLT that applies to regression. It turns out that with a large enough sample size, in this case the number of teams, we can construct a confidence interval. Use the function `tidy` to report a confidence interval for the effect of SB on runs based exclusively on the 1999 data. What are your thoughts now on the effectiveness of recruiting players that can steal bases?


```{r}
fitSB <- lm(R_per_game ~ SB_per_game, data = teams99)
confint_tidy(fitSB)
tidy(fitSB, conf.int = T)
```

Again it appears that stolen bases per game are insignificant in determining runs scored per game as the confidence interval contains 0 like it did for part (b).

## Problem 1D

Back in 2002 (the year of the [money ball](https://en.wikipedia.org/wiki/Moneyball) story described above), bases on balls (BB) did not receive as much attention as other statistics. Repeat the above analysis we performed in 1C for BB per game in 1999. Do BB have a larger effect on runs than SB?


```{r}
teams99 <- teams99 %>% mutate(BB_per_game = BB/G)
fitBB <- lm(R_per_game ~ BB_per_game, data = teams99)
confint_tidy(fitBB)
tidy(fitBB, conf.int = T)
```

Yes walks have a larger effect on runs than stolen bases because 1) the CI for walks does not contain 0 meaning that the relationship between walks per game and runs per game is significant, unlike stolen bases per game, and 2) the walks CI is above 0 meaning that for every additional walk a team receives per game they are increasing their mean number of runs per game.

## Problem 1E

Association is not causation. It turns out that HR hitters also obtain many BB. We know for a fact that HRs cause runs because, by definition, they produce at least one. We can see this by simply plotting these two statistics for all players with more than 500 plate appearances (`BB+AB`):

```{r}
Batting %>%
  filter(yearID >= 1961 & BB+AB > 500 & !is.na(HR) & !is.na(BB)) %>% 
  mutate(HR = factor(pmin(HR, 40))) %>%
  ggplot(aes(HR, BB)) +
  geom_boxplot()
```

So, is the relationship we saw above for BB and runs due to teams having more HRs also having more BBs? One way we can explore this is by keeping HR fixed and examining the relationship within the strata. For example, if we look only at teams with 150 HRs, do more BBs produce more runs?

We can't perform this analysis on a single year, because there are not enough teams to obtain strata with more than one or two teams. Instead we will combine all data across years since 1961. 

Group data by the number of HRs and perform a regression analysis in each stratum to determine the effect of BB per game on runs per game. Use 10th, 20th, ... quantiles to split the data into 10 groups. Hint: use the function `cut` and `quantile` to create the strata. Does the relationship between BB and runs seem linear within each strata?

```{r}
# Add walks to the 61onward dataset
teams61onward <- teams %>% filter(yearID >= 1961) %>% 
  mutate(SB_per_game = SB/G, R_per_game = R/G, BB_per_game = BB/G) 

# Cut the data by HR deciles
HRgroups <- teams61onward %>% mutate(HRdeciles = cut(HR, breaks = quantile(HR, probs = seq(0,1, by = 0.1), include.lowest=T)))

# Fit the model for each of the deciles
HRwalksruns <- HRgroups %>%
  nest(-HRdeciles) %>% 
  mutate(
    fit = map(data, ~ lm(R_per_game ~ BB_per_game, data = .x)),
    tidied = map(fit, tidy)
  ) %>% 
  unnest(tidied)
HRwalksruns %>% filter(term == "BB_per_game")

# Plot the data for each of the deciles
ggplot(data = HRgroups, aes(BB_per_game,R_per_game, colour = HRdeciles)) + geom_smooth(method = "lm")

```

Thus it appears that the relationship between walks and runs is linear within each strata.

## Problem 1F

In problem 1E, we saw that the effect of BB on runs appears to be about the same in each strata. The relationship between HR and R is also, not surprisingly, linear:

```{r}
Teams %>%
  filter(yearID >= 1961) %>% 
  mutate(R = R / G, HR = HR / G) %>%
  ggplot(aes(HR, R)) +
  geom_point()
```

These two combined implies that a sensible linear model says:

$$
\mbox{Runs} = \beta_0 + \beta_{BB} \mbox{BB} + \beta_{HR}{HR} + \varepsilon
$$

In this model, we _adjust_ for HRs by including it as linear term. Note that we have already shown data that support this model. In general, simply fitting such a model does not necessarily adjust for a possible confounder. The model must also be approximately correct.

We can fit this model like this:

```{r}
fit <- Teams %>%
  filter(yearID >= 1961) %>% 
  mutate(R = R / G, BB = BB / G, HR = HR / G) %>%
  lm(R ~ BB + HR, data = .)
summary(fit)
```

Note that the summary shows a very strong HR effect but also a decent BB effect. Now, what happens if we include singles (`H-X2B-X3B-HR`), extra bases (doubles plus triples, `X2B + X3B`), and HRs per game in our model? What does the model say about which of these characteristics should receive more weight? 

Also, fit the model to each year independently to check for consistency from year to year. Does the model appear consistent over time?

```{r}
fit2 <- Teams %>%
  filter(yearID >= 1961) %>% 
  mutate(R = R / G, BB = BB / G, HR = HR / G, extra_bases = (X2B + X3B)/G, singles = (H-X2B-X3B-HR)/G) %>%
  lm(R ~ BB + singles + extra_bases + HR , data = .)
summary(fit2)
```

Thus this model says that extra bases should receive more weight as the estimate for extra bases `r fit2$coefficients[4]` is greater than the estimate of singles `r fit2$coefficients[3]` which indicates that an increase extra bases, rather than singles, has a larger increase in the mean number of runs per game.

```{r}
# New dataset
newteams <- Teams %>%
  filter(yearID >= 1961) %>% 
  mutate(R = R / G, BB = BB / G, HR = HR / G, extra_bases = (X2B + X3B)/G, singles = (H-X2B-X3B-HR)/G)

fit_by_year <- newteams %>%
  nest(-yearID) %>% 
  mutate(
    fit = map(data, ~ lm(R ~ BB + singles + extra_bases + HR, data = .x)),
    tidied = map(fit, tidy)
  ) %>% 
  unnest(tidied)

fit_by_year %>% filter(term != "(Intercept)") %>% ggplot(aes(yearID, estimate, colour = term)) + geom_line()
```

Based on this graph it appears that the model estimates have fluctuated a decent amount over time. However, the fluctuations are over a relatively small range of values, in most cases no more than 0.5 in total change of each of the estimates. Thus, an argument could be made that the estimates of the model has remained relatively consistent due to the lack of very large changes. Additionally, looking at the graph over the entire time period, the estimates have remained within distinct ranges with only a few "outlier" years. But if one were to simply look at this graph without any other interpretations, the estimates would not appear very consistent.
